{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TOKENIZERS_PARALLELISM'] = 'false'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-05 23:52:08.953567: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-05 23:52:10.142863: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import evaluate\n",
    "from transformers import (\n",
    "    AutoModelForSequenceClassification, AutoTokenizer,\n",
    "    Trainer, TrainingArguments,\n",
    "    BitsAndBytesConfig\n",
    ")\n",
    "from peft import (\n",
    "    prepare_model_for_kbit_training, LoraConfig, get_peft_model, TaskType\n",
    ")\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    f1_score,\n",
    "    classification_report,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x79145f200a10>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SEED = 42\n",
    "MAX_LENGTH = 32768\n",
    "INSTRUCTION = 'Classify the aspect mentioned in the given Steam Review into up to of the eight aspects: recommended, story, gameplay, visual, audio, technical, price, and suggestion.'  # This mimic paper's string instruction\n",
    "LABELS = [\n",
    "    'label_recommended', 'label_story', 'label_gameplay', 'label_visual',\n",
    "    'label_audio', 'label_technical', 'label_price', 'label_suggestion'\n",
    "]\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(examples, tokenizer):\n",
    "    outputs = tokenizer(\n",
    "        [INSTRUCTION + s for s in examples['cleaned_review']],\n",
    "        truncation=True, max_length=MAX_LENGTH\n",
    "    )\n",
    "    return outputs\n",
    "\n",
    "\n",
    "def load_model():\n",
    "    quantization_config = BitsAndBytesConfig(\n",
    "        load_in_4bit=True,\n",
    "        bnb_4bit_quant_type='nf4',\n",
    "        bnb_4bit_use_double_quant=True,\n",
    "        bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "    )\n",
    "    lora_config = LoraConfig(\n",
    "        #\n",
    "        r=16,\n",
    "        lora_alpha=8,\n",
    "        lora_dropout=0.05,\n",
    "        bias='none',\n",
    "        # use_rslora=True,\n",
    "        task_type='CAUSAL_LM',\n",
    "        target_modules=[\n",
    "            'q_proj',\n",
    "            # 'k_proj',\n",
    "            'v_proj',\n",
    "            # 'o_proj',\n",
    "            # 'gate_proj',\n",
    "            # 'up_proj',\n",
    "            # 'down_proj',\n",
    "            # 'embed_tokens',\n",
    "            # 'lm_head',\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        'intfloat/e5-mistral-7b-instruct', trust_remote_code=True,\n",
    "        num_labels=8, problem_type='multi_label_classification',\n",
    "        quantization_config=quantization_config,\n",
    "        # token='HF_XXX'\n",
    "    )\n",
    "    model.gradient_checkpointing_enable()\n",
    "    model = prepare_model_for_kbit_training(model)\n",
    "    model = get_peft_model(model, lora_config)\n",
    "    model.print_trainable_parameters()\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1/(1 + np.exp(-x))\n",
    "\n",
    "\n",
    "metric = evaluate.combine(['precision', 'recall', 'f1'])\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = sigmoid(predictions)\n",
    "    predictions = (predictions > 0.5).astype(int).reshape(-1)\n",
    "    return metric.compute(predictions=predictions, references=labels.astype(int).reshape(-1), average='macro')\n",
    "\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x)) \n",
    "sigmoid_v = np.vectorize(sigmoid)\n",
    "\n",
    "\n",
    "def evaluate(y_test, y_pred, labels):\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f'Overall accuracy: {accuracy}')\n",
    "    for idx, label in enumerate(labels):\n",
    "        label_accuracy = accuracy_score(y_test[:, idx], y_pred[:, idx])\n",
    "        print(f'Accuracy {label}: {label_accuracy}')\n",
    "\n",
    "    f1 = f1_score(y_test, y_pred, average='macro')\n",
    "    print(f'F1 macro: {f1}')\n",
    "    print(\n",
    "        classification_report(y_test, y_pred, target_names=labels, digits=4, zero_division=0)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`low_cpu_mem_usage` was None, now set to True since model is quantized.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5046429ee064e4699b6d87c331b1c78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of MistralForSequenceClassification were not initialized from the model checkpoint at intfloat/e5-mistral-7b-instruct and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 6,815,744 || all params: 7,117,508,608 || trainable%: 0.0958\n"
     ]
    }
   ],
   "source": [
    "model = load_model()\n",
    "tokenizer = AutoTokenizer.from_pretrained('intfloat/e5-mistral-7b-instruct')\n",
    "ds_all = load_dataset('ilos-vigil/steam-review-aspect-dataset')\n",
    "ds_all = ds_all.map(encode, batched=True, fn_kwargs={'tokenizer': tokenizer})\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    #\n",
    "    output_dir='final',\n",
    "    logging_steps=5,\n",
    "    report_to='tensorboard',\n",
    "    #\n",
    "    dataloader_drop_last=False,\n",
    "    eval_strategy='no',\n",
    "    #\n",
    "    bf16=True,\n",
    "    per_device_train_batch_size=1,\n",
    "    per_device_eval_batch_size=1,\n",
    "    gradient_accumulation_steps=16,\n",
    "    eval_accumulation_steps=16,\n",
    "    gradient_checkpointing=True,\n",
    "    optim=\"paged_adamw_8bit\",\n",
    "    # alternative approach\n",
    "    num_train_epochs=2,\n",
    "    learning_rate=0.0002,\n",
    "    weight_decay=0.0,\n",
    "    warmup_steps=5,\n",
    "    adam_beta1=0.9,\n",
    "    adam_beta2=0.95,\n",
    ")\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    tokenizer=tokenizer,\n",
    "    train_dataset=ds_all['train'],\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8083a6155e824f588f2cc738e20f8514",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/112 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/db4/Git/srec/steam-review-aspect-dataset-github/.venv/lib/python3.10/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.7943, 'grad_norm': 5.335930347442627, 'learning_rate': 0.0002, 'epoch': 0.09}\n",
      "{'loss': 1.7291, 'grad_norm': 5.490852355957031, 'learning_rate': 0.00019065420560747664, 'epoch': 0.18}\n",
      "{'loss': 1.4007, 'grad_norm': 5.1768951416015625, 'learning_rate': 0.0001813084112149533, 'epoch': 0.27}\n",
      "{'loss': 1.0765, 'grad_norm': 3.4315829277038574, 'learning_rate': 0.00017196261682242992, 'epoch': 0.36}\n",
      "{'loss': 0.8738, 'grad_norm': 3.458270788192749, 'learning_rate': 0.00016261682242990654, 'epoch': 0.44}\n",
      "{'loss': 0.8445, 'grad_norm': 4.763637542724609, 'learning_rate': 0.00015327102803738317, 'epoch': 0.53}\n",
      "{'loss': 0.7836, 'grad_norm': 3.2394015789031982, 'learning_rate': 0.00014392523364485982, 'epoch': 0.62}\n",
      "{'loss': 0.6852, 'grad_norm': 3.784304618835449, 'learning_rate': 0.00013457943925233645, 'epoch': 0.71}\n",
      "{'loss': 0.6499, 'grad_norm': 4.912858486175537, 'learning_rate': 0.00012523364485981308, 'epoch': 0.8}\n",
      "{'loss': 0.5499, 'grad_norm': 2.4500560760498047, 'learning_rate': 0.00011588785046728972, 'epoch': 0.89}\n",
      "{'loss': 0.539, 'grad_norm': 2.827589750289917, 'learning_rate': 0.00010654205607476636, 'epoch': 0.98}\n",
      "{'loss': 0.5016, 'grad_norm': 2.1040642261505127, 'learning_rate': 9.7196261682243e-05, 'epoch': 1.07}\n",
      "{'loss': 0.507, 'grad_norm': 2.6254703998565674, 'learning_rate': 8.785046728971964e-05, 'epoch': 1.16}\n",
      "{'loss': 0.4568, 'grad_norm': 2.2793939113616943, 'learning_rate': 7.850467289719626e-05, 'epoch': 1.24}\n",
      "{'loss': 0.466, 'grad_norm': 1.8915287256240845, 'learning_rate': 6.91588785046729e-05, 'epoch': 1.33}\n",
      "{'loss': 0.4659, 'grad_norm': 2.3446462154388428, 'learning_rate': 5.981308411214953e-05, 'epoch': 1.42}\n",
      "{'loss': 0.4287, 'grad_norm': 3.645676851272583, 'learning_rate': 5.046728971962617e-05, 'epoch': 1.51}\n",
      "{'loss': 0.442, 'grad_norm': 1.836161494255066, 'learning_rate': 4.11214953271028e-05, 'epoch': 1.6}\n",
      "{'loss': 0.4059, 'grad_norm': 2.217334270477295, 'learning_rate': 3.177570093457944e-05, 'epoch': 1.69}\n",
      "{'loss': 0.4285, 'grad_norm': 2.406750202178955, 'learning_rate': 2.2429906542056075e-05, 'epoch': 1.78}\n",
      "{'loss': 0.379, 'grad_norm': 3.0447838306427, 'learning_rate': 1.308411214953271e-05, 'epoch': 1.87}\n",
      "{'loss': 0.4523, 'grad_norm': 3.5861263275146484, 'learning_rate': 3.7383177570093455e-06, 'epoch': 1.96}\n",
      "{'train_runtime': 3867.0998, 'train_samples_per_second': 0.465, 'train_steps_per_second': 0.029, 'train_loss': 0.7603069229849747, 'epoch': 1.99}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=112, training_loss=0.7603069229849747, metrics={'train_runtime': 3867.0998, 'train_samples_per_second': 0.465, 'train_steps_per_second': 0.029, 'total_flos': 2.887580881900339e+16, 'train_loss': 0.7603069229849747, 'epoch': 1.991111111111111})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()\n",
    "with torch.no_grad():\n",
    "    torch.cuda.empty_cache()\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4d63947ab6a4d5f86c670ee2517d021",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall accuracy: 0.175\n",
      "Accuracy label_recommended: 0.85\n",
      "Accuracy label_story: 0.78\n",
      "Accuracy label_gameplay: 0.83\n",
      "Accuracy label_visual: 0.64\n",
      "Accuracy label_audio: 0.76\n",
      "Accuracy label_technical: 0.795\n",
      "Accuracy label_price: 0.83\n",
      "Accuracy label_suggestion: 0.895\n",
      "F1 macro: 0.602655223199517\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "label_recommended     0.8782    0.9257    0.9013       148\n",
      "      label_story     0.7778    0.7079    0.7412        89\n",
      "   label_gameplay     0.8333    0.9740    0.8982       154\n",
      "     label_visual     0.5843    0.5977    0.5909        87\n",
      "      label_audio     0.5455    0.3529    0.4286        51\n",
      "  label_technical     0.6481    0.6140    0.6306        57\n",
      "      label_price     0.6444    0.6170    0.6304        47\n",
      " label_suggestion     0.0000    0.0000    0.0000        21\n",
      "\n",
      "        micro avg     0.7586    0.7401    0.7492       654\n",
      "        macro avg     0.6140    0.5987    0.6027       654\n",
      "     weighted avg     0.7239    0.7401    0.7286       654\n",
      "      samples avg     0.7492    0.7324    0.7155       654\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = trainer.predict(ds_all['test'])\n",
    "y_pred = np.where(\n",
    "    sigmoid_v(y_pred.predictions) > 0.5, 1, 0\n",
    ").astype(np.int32)\n",
    "\n",
    "evaluate(np.array(ds_all['test']['labels']), y_pred, LABELS)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
