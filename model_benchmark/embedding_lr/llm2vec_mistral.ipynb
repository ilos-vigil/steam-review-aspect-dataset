{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%set_env TOKENIZERS_PARALLELISM=false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel, AutoConfig, BitsAndBytesConfig\n",
    "from llm2vec import LLM2Vec\n",
    "from peft import PeftModel\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    f1_score,\n",
    "    classification_report,\n",
    ")\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "SEED = 42\n",
    "HF_TOKEN = 'hf_XXX'\n",
    "BATCH_SIZE = 8\n",
    "MODEL_NAME = 'McGill-NLP/LLM2Vec-Mistral-7B-Instruct-v2-mntp'\n",
    "MODEL_ID = 'McGill-NLP/LLM2Vec-Mistral-7B-Instruct-v2-mntp-supervised'\n",
    "INSTRUCTION = 'Classify the aspect mentioned in the given Steam Review into up to of the eight aspects: recommended, story, gameplay, visual, audio, technical, price, and suggestion.'  # This mimic paper's string instruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('../../dataset/v1/train.csv')\n",
    "df_test = pd.read_csv('../../dataset/v1/test.csv')\n",
    "\n",
    "labels = df_train.columns[3:].to_list()\n",
    "y_train = df_train[labels].to_numpy()\n",
    "y_test = df_test[labels].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/db4/Git/srec/steam-review-aspect-dataset-github/.venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f532931ccc54d31b8871412d69cecc4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19a4da8b05074c5293d6904c72574319",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at mistralai/Mistral-7B-Instruct-v0.2 were not used when initializing MistralEncoderModel: ['lm_head.weight']\n",
      "- This IS expected if you are initializing MistralEncoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing MistralEncoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/mnt/db4/Git/srec/steam-review-aspect-dataset-github/.venv/lib/python3.10/site-packages/peft/tuners/lora/bnb.py:325: UserWarning: Merge lora module to 4-bit linear may get different generations due to rounding errors.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    MODEL_NAME\n",
    ")\n",
    "config = AutoConfig.from_pretrained(\n",
    "    MODEL_NAME, trust_remote_code=True\n",
    ")\n",
    "quantization_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type='nf4',\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")\n",
    "model = AutoModel.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    trust_remote_code=True,\n",
    "    config=config,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=\"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "    token=HF_TOKEN,\n",
    "    quantization_config=quantization_config\n",
    ")\n",
    "model = PeftModel.from_pretrained(\n",
    "    model,\n",
    "    MODEL_NAME,\n",
    ")\n",
    "model = model.merge_and_unload()\n",
    "model = PeftModel.from_pretrained(model, MODEL_ID)\n",
    "\n",
    "# Wrapper for encoding and pooling operations\n",
    "l2v = LLM2Vec(model, tokenizer, pooling_mode='mean', max_length=512)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(X_train, y_train, X_test, y_test, labels):\n",
    "    clf = LogisticRegression(\n",
    "        random_state=SEED,\n",
    "        max_iter=100\n",
    "    )\n",
    "    ovr = OneVsRestClassifier(clf, n_jobs=-1)\n",
    "\n",
    "    ovr.fit(X_train, y_train)\n",
    "    y_pred = ovr.predict(X_test)\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f'Overall accuracy: {accuracy}')\n",
    "    for idx, label in enumerate(labels):\n",
    "        label_accuracy = accuracy_score(y_test[:, idx], y_pred[:, idx])\n",
    "        print(f'Accuracy {label}: {label_accuracy}')\n",
    "\n",
    "    f1 = f1_score(y_test, y_pred, average='macro')\n",
    "    print(f'F1 macro: {f1}')\n",
    "    print(\n",
    "        classification_report(y_test, y_pred, target_names=labels, digits=4, zero_division=0)\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "847fcf346d4644499b552cee230823bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/113 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-01 00:03:52.419214: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-01 00:03:53.871412: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa4c787b1ea248a0b887f0cd2cd824ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_train = l2v.encode(\n",
    "    # df_train['cleaned_review'].to_list(),\n",
    "    [\n",
    "        INSTRUCTION + s for s in\n",
    "        df_train['cleaned_review'].to_list()\n",
    "    ],\n",
    "    batch_size=BATCH_SIZE\n",
    ")\n",
    "# X_train = torch.nn.functional.normalize(X_train, p=2, dim=1).numpy()\n",
    "X_test = l2v.encode(\n",
    "    # df_test['cleaned_review'].to_list(),\n",
    "    [\n",
    "        INSTRUCTION + s for s in\n",
    "        df_test['cleaned_review'].to_list()\n",
    "    ],\n",
    "    batch_size=BATCH_SIZE\n",
    ")\n",
    "# X_test = torch.nn.functional.normalize(X_test, p=2, dim=1).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall accuracy: 0.295\n",
      "Accuracy label_recommended: 0.895\n",
      "Accuracy label_story: 0.79\n",
      "Accuracy label_gameplay: 0.89\n",
      "Accuracy label_visual: 0.795\n",
      "Accuracy label_audio: 0.83\n",
      "Accuracy label_technical: 0.865\n",
      "Accuracy label_price: 0.84\n",
      "Accuracy label_suggestion: 0.85\n",
      "F1 macro: 0.6927673032099368\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "label_recommended     0.9441    0.9122    0.9278       148\n",
      "      label_story     0.7831    0.7303    0.7558        89\n",
      "   label_gameplay     0.9074    0.9545    0.9304       154\n",
      "     label_visual     0.7738    0.7471    0.7602        87\n",
      "      label_audio     0.7179    0.5490    0.6222        51\n",
      "  label_technical     0.7500    0.7895    0.7692        57\n",
      "      label_price     0.7143    0.5319    0.6098        47\n",
      " label_suggestion     0.2000    0.1429    0.1667        21\n",
      "\n",
      "        micro avg     0.8261    0.7844    0.8047       654\n",
      "        macro avg     0.7238    0.6697    0.6928       654\n",
      "     weighted avg     0.8159    0.7844    0.7978       654\n",
      "      samples avg     0.8147    0.7736    0.7706       654\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate(X_train, y_train, X_test, y_test, labels)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
