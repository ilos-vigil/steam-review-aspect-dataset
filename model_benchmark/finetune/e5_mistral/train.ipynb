{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TOKENIZERS_PARALLELISM'] = 'false'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-05 22:57:49.254295: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-05 22:57:50.481144: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import evaluate\n",
    "from transformers import (\n",
    "    AutoModelForSequenceClassification, AutoTokenizer,\n",
    "    Trainer, TrainingArguments,\n",
    "    BitsAndBytesConfig\n",
    ")\n",
    "from peft import (\n",
    "    prepare_model_for_kbit_training, LoraConfig, get_peft_model, TaskType\n",
    ")\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    f1_score,\n",
    "    classification_report,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7e95107dc9d0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SEED = 42\n",
    "MAX_LENGTH = 32768\n",
    "INSTRUCTION = 'Classify the aspect mentioned in the given Steam Review into up to of the eight aspects: recommended, story, gameplay, visual, audio, technical, price, and suggestion.'  # This mimic paper's string instruction\n",
    "LABELS = [\n",
    "    'label_recommended', 'label_story', 'label_gameplay', 'label_visual',\n",
    "    'label_audio', 'label_technical', 'label_price', 'label_suggestion'\n",
    "]\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(examples, tokenizer):\n",
    "    outputs = tokenizer(\n",
    "        [INSTRUCTION + s for s in examples['cleaned_review']],\n",
    "        truncation=True, max_length=MAX_LENGTH\n",
    "    )\n",
    "    return outputs\n",
    "\n",
    "\n",
    "def load_model():\n",
    "    quantization_config = BitsAndBytesConfig(\n",
    "        load_in_4bit=True,\n",
    "        bnb_4bit_quant_type='nf4',\n",
    "        bnb_4bit_use_double_quant=True,\n",
    "        bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "    )\n",
    "    lora_config = LoraConfig(\n",
    "        r=8,\n",
    "        lora_alpha=16,\n",
    "        lora_dropout=0.05,\n",
    "        bias='none',\n",
    "        use_rslora=True,\n",
    "        task_type='CAUSAL_LM',\n",
    "        target_modules=[\n",
    "            'q_proj',\n",
    "            'k_proj',\n",
    "            'v_proj',\n",
    "            'o_proj',\n",
    "            'gate_proj',\n",
    "            'up_proj',\n",
    "            'down_proj',\n",
    "            'embed_tokens',\n",
    "            'lm_head',\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        'intfloat/e5-mistral-7b-instruct', trust_remote_code=True,\n",
    "        num_labels=8, problem_type='multi_label_classification',\n",
    "        quantization_config=quantization_config,\n",
    "        # token='HF_XXX'\n",
    "    )\n",
    "    model.gradient_checkpointing_enable()\n",
    "    model = prepare_model_for_kbit_training(model)\n",
    "    model = get_peft_model(model, lora_config)\n",
    "    model.print_trainable_parameters()\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1/(1 + np.exp(-x))\n",
    "\n",
    "\n",
    "metric = evaluate.combine(['precision', 'recall', 'f1'])\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = sigmoid(predictions)\n",
    "    predictions = (predictions > 0.5).astype(int).reshape(-1)\n",
    "    return metric.compute(predictions=predictions, references=labels.astype(int).reshape(-1), average='macro')\n",
    "\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x)) \n",
    "sigmoid_v = np.vectorize(sigmoid)\n",
    "\n",
    "\n",
    "def evaluate(y_test, y_pred, labels):\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f'Overall accuracy: {accuracy}')\n",
    "    for idx, label in enumerate(labels):\n",
    "        label_accuracy = accuracy_score(y_test[:, idx], y_pred[:, idx])\n",
    "        print(f'Accuracy {label}: {label_accuracy}')\n",
    "\n",
    "    f1 = f1_score(y_test, y_pred, average='macro')\n",
    "    print(f'F1 macro: {f1}')\n",
    "    print(\n",
    "        classification_report(y_test, y_pred, target_names=labels, digits=4, zero_division=0)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`low_cpu_mem_usage` was None, now set to True since model is quantized.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e751d04c4944d1798bf8d5aaba2d8b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of MistralForSequenceClassification were not initialized from the model checkpoint at intfloat/e5-mistral-7b-instruct and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 21,260,288 || all params: 7,131,953,152 || trainable%: 0.2981\n"
     ]
    }
   ],
   "source": [
    "model = load_model()\n",
    "tokenizer = AutoTokenizer.from_pretrained('intfloat/e5-mistral-7b-instruct')\n",
    "ds_all = load_dataset('ilos-vigil/steam-review-aspect-dataset')\n",
    "ds_all = ds_all.map(encode, batched=True, fn_kwargs={'tokenizer': tokenizer})\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    #\n",
    "    output_dir='final',\n",
    "    logging_steps=5,\n",
    "    report_to='tensorboard',\n",
    "    #\n",
    "    dataloader_drop_last=False,\n",
    "    eval_strategy='no',\n",
    "    #\n",
    "    bf16=True,\n",
    "    per_device_train_batch_size=1,\n",
    "    per_device_eval_batch_size=1,\n",
    "    gradient_accumulation_steps=8,\n",
    "    eval_accumulation_steps=8,\n",
    "    gradient_checkpointing=True,\n",
    "    optim=\"paged_adamw_8bit\",\n",
    "    num_train_epochs=1,\n",
    "    # from few ray tune trial\n",
    "    learning_rate=0.00005,\n",
    "    weight_decay=0.0003,\n",
    "    warmup_ratio=0.05,\n",
    ")\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    tokenizer=tokenizer,\n",
    "    train_dataset=ds_all['train'],\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e5c9d3124c44c64a174a14ca256dc3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/112 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/db4/Git/srec/steam-review-aspect-dataset-github/.venv/lib/python3.10/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.6339, 'grad_norm': 937.6458740234375, 'learning_rate': 4.166666666666667e-05, 'epoch': 0.04}\n",
      "{'loss': 1.6996, 'grad_norm': 522.1160888671875, 'learning_rate': 4.811320754716982e-05, 'epoch': 0.09}\n",
      "{'loss': 1.2485, 'grad_norm': 666.1519775390625, 'learning_rate': 4.575471698113208e-05, 'epoch': 0.13}\n",
      "{'loss': 1.2215, 'grad_norm': 811.1981201171875, 'learning_rate': 4.3396226415094345e-05, 'epoch': 0.18}\n",
      "{'loss': 1.0486, 'grad_norm': 772.4200439453125, 'learning_rate': 4.103773584905661e-05, 'epoch': 0.22}\n",
      "{'loss': 0.8087, 'grad_norm': 690.603271484375, 'learning_rate': 3.867924528301887e-05, 'epoch': 0.27}\n",
      "{'loss': 0.8281, 'grad_norm': 495.5755920410156, 'learning_rate': 3.632075471698113e-05, 'epoch': 0.31}\n",
      "{'loss': 0.875, 'grad_norm': 661.9572143554688, 'learning_rate': 3.39622641509434e-05, 'epoch': 0.36}\n",
      "{'loss': 0.8121, 'grad_norm': 905.1956787109375, 'learning_rate': 3.160377358490566e-05, 'epoch': 0.4}\n",
      "{'loss': 0.7801, 'grad_norm': 287.1793212890625, 'learning_rate': 2.9245283018867926e-05, 'epoch': 0.44}\n",
      "{'loss': 0.7556, 'grad_norm': 514.3616943359375, 'learning_rate': 2.688679245283019e-05, 'epoch': 0.49}\n",
      "{'loss': 0.6812, 'grad_norm': 218.86203002929688, 'learning_rate': 2.4528301886792453e-05, 'epoch': 0.53}\n",
      "{'loss': 0.6568, 'grad_norm': 953.1724243164062, 'learning_rate': 2.216981132075472e-05, 'epoch': 0.58}\n",
      "{'loss': 0.5908, 'grad_norm': 399.4234619140625, 'learning_rate': 1.9811320754716984e-05, 'epoch': 0.62}\n",
      "{'loss': 0.7002, 'grad_norm': 553.6637573242188, 'learning_rate': 1.7452830188679244e-05, 'epoch': 0.67}\n",
      "{'loss': 0.5511, 'grad_norm': 245.02284240722656, 'learning_rate': 1.509433962264151e-05, 'epoch': 0.71}\n",
      "{'loss': 0.5643, 'grad_norm': 455.67822265625, 'learning_rate': 1.2735849056603775e-05, 'epoch': 0.76}\n",
      "{'loss': 0.6454, 'grad_norm': 173.04620361328125, 'learning_rate': 1.0377358490566038e-05, 'epoch': 0.8}\n",
      "{'loss': 0.7031, 'grad_norm': 227.36700439453125, 'learning_rate': 8.018867924528302e-06, 'epoch': 0.84}\n",
      "{'loss': 0.4927, 'grad_norm': 217.8157196044922, 'learning_rate': 5.660377358490566e-06, 'epoch': 0.89}\n",
      "{'loss': 0.5181, 'grad_norm': 118.52037048339844, 'learning_rate': 3.30188679245283e-06, 'epoch': 0.93}\n",
      "{'loss': 0.5779, 'grad_norm': 181.52679443359375, 'learning_rate': 9.433962264150943e-07, 'epoch': 0.98}\n",
      "{'train_runtime': 2299.8602, 'train_samples_per_second': 0.391, 'train_steps_per_second': 0.049, 'train_loss': 0.8731554592294353, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=112, training_loss=0.8731554592294353, metrics={'train_runtime': 2299.8602, 'train_samples_per_second': 0.391, 'train_steps_per_second': 0.049, 'total_flos': 1.4470443293601792e+16, 'train_loss': 0.8731554592294353, 'epoch': 0.9955555555555555})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()\n",
    "with torch.no_grad():\n",
    "    torch.cuda.empty_cache()\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e4bee55c17640a2a8ec45b8f14d6f16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall accuracy: 0.13\n",
      "Accuracy label_recommended: 0.835\n",
      "Accuracy label_story: 0.725\n",
      "Accuracy label_gameplay: 0.81\n",
      "Accuracy label_visual: 0.635\n",
      "Accuracy label_audio: 0.78\n",
      "Accuracy label_technical: 0.77\n",
      "Accuracy label_price: 0.72\n",
      "Accuracy label_suggestion: 0.89\n",
      "F1 macro: 0.49433687427810113\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "label_recommended     0.8324    0.9730    0.8972       148\n",
      "      label_story     0.6932    0.6854    0.6893        89\n",
      "   label_gameplay     0.8295    0.9481    0.8848       154\n",
      "     label_visual     0.6207    0.4138    0.4966        87\n",
      "      label_audio     0.7333    0.2157    0.3333        51\n",
      "  label_technical     0.7619    0.2807    0.4103        57\n",
      "      label_price     0.3333    0.1915    0.2432        47\n",
      " label_suggestion     0.0000    0.0000    0.0000        21\n",
      "\n",
      "        micro avg     0.7567    0.6468    0.6974       654\n",
      "        macro avg     0.6005    0.4635    0.4943       654\n",
      "     weighted avg     0.7081    0.6468    0.6505       654\n",
      "      samples avg     0.7442    0.6380    0.6614       654\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = trainer.predict(ds_all['test'])\n",
    "y_pred = np.where(\n",
    "    sigmoid_v(y_pred.predictions) > 0.5, 1, 0\n",
    ").astype(np.int32)\n",
    "\n",
    "evaluate(np.array(ds_all['test']['labels']), y_pred, LABELS)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
