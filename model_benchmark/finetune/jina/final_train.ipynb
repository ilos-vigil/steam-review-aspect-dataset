{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: TOKENIZERS_PARALLELISM=false\n"
     ]
    }
   ],
   "source": [
    "%set_env TOKENIZERS_PARALLELISM=false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-11 21:15:06.966188: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-11 21:15:07.891273: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import evaluate\n",
    "from transformers import (\n",
    "    AutoModelForSequenceClassification, AutoTokenizer,\n",
    "    Trainer, TrainingArguments\n",
    ")\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    f1_score,\n",
    "    classification_report,\n",
    ")\n",
    "\n",
    "SEED = 42\n",
    "MAX_LENGTH = 8192\n",
    "LABELS = [\n",
    "    'label_recommended', 'label_story', 'label_gameplay', 'label_visual',\n",
    "    'label_audio', 'label_technical', 'label_price', 'label_suggestion'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x79f725c049b0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(examples, tokenizer):\n",
    "    outputs = tokenizer(examples['cleaned_review'], truncation=True)\n",
    "    return outputs\n",
    "\n",
    "\n",
    "def evaluate(y_test, y_pred, labels):\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f'Overall accuracy: {accuracy}')\n",
    "    for idx, label in enumerate(labels):\n",
    "        label_accuracy = accuracy_score(y_test[:, idx], y_pred[:, idx])\n",
    "        print(f'Accuracy {label}: {label_accuracy}')\n",
    "\n",
    "    f1 = f1_score(y_test, y_pred, average='macro')\n",
    "    print(f'F1 macro: {f1}')\n",
    "    print(\n",
    "        classification_report(y_test, y_pred, target_names=labels, digits=4, zero_division=0)\n",
    "    )\n",
    "\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x)) \n",
    "sigmoid_v = np.vectorize(sigmoid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(\n",
    "    model_name, gradient_accumulation_steps, num_train_epochs,\n",
    "    learning_rate, weight_decay, warmup_ratio\n",
    "):\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        model_name, trust_remote_code=True,\n",
    "        num_labels=8, problem_type='multi_label_classification'\n",
    "    )\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    ds_all = load_dataset('ilos-vigil/steam-review-aspect-dataset')\n",
    "    ds_all = ds_all.map(encode, batched=True, fn_kwargs={'tokenizer': tokenizer})\n",
    "\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=f'final_{model_name.split(\"/\")[-1]}',\n",
    "        eval_strategy='no',\n",
    "        bf16=True,\n",
    "        dataloader_drop_last=False,\n",
    "        report_to='tensorboard',\n",
    "        per_device_train_batch_size=1,\n",
    "        per_device_eval_batch_size=1,\n",
    "        gradient_checkpointing=True,\n",
    "        # param from ray tune\n",
    "        gradient_accumulation_steps=gradient_accumulation_steps,\n",
    "        eval_accumulation_steps=gradient_accumulation_steps,\n",
    "        num_train_epochs=num_train_epochs,\n",
    "        learning_rate=learning_rate,\n",
    "        weight_decay=weight_decay,\n",
    "        warmup_ratio=warmup_ratio\n",
    "    )\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        tokenizer=tokenizer,\n",
    "        train_dataset=ds_all['train']\n",
    "    )\n",
    "    trainer.train()\n",
    "\n",
    "    y_pred = trainer.predict(ds_all['test'])\n",
    "    y_pred = np.where(\n",
    "        sigmoid_v(y_pred.predictions) > 0.5, 1, 0\n",
    "    ).astype(np.int32)\n",
    "\n",
    "    evaluate(np.array(ds_all['test']['labels']), y_pred, LABELS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of JinaBertForSequenceClassification were not initialized from the model checkpoint at jinaai/jina-embeddings-v2-base-en and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2d5bbbdea1b4b6f98816db2b5d669a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/900 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66c3a1be741b45859ae64be29a07ec2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/200 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using an old version of the checkpointing format that is deprecated (We will also silently ignore `gradient_checkpointing_kwargs` in case you passed it).Please update to the new format on your modeling file. To use the new format, you need to completely remove the definition of the method `_set_gradient_checkpointing` in your model.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a398acc227f54f30b5b39c20f4eaf7b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/280 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/db4/Git/srec/steam-review-aspect-dataset-github/.venv/lib/python3.10/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 466.6251, 'train_samples_per_second': 9.644, 'train_steps_per_second': 0.6, 'train_loss': 0.34732862200055803, 'epoch': 4.98}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3f822dd49d6411ba2986417d7cbd346",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall accuracy: 0.335\n",
      "Accuracy label_recommended: 0.89\n",
      "Accuracy label_story: 0.855\n",
      "Accuracy label_gameplay: 0.87\n",
      "Accuracy label_visual: 0.84\n",
      "Accuracy label_audio: 0.955\n",
      "Accuracy label_technical: 0.87\n",
      "Accuracy label_price: 0.88\n",
      "Accuracy label_suggestion: 0.885\n",
      "F1 macro: 0.7354135529174992\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "label_recommended     0.9091    0.9459    0.9272       148\n",
      "      label_story     0.8488    0.8202    0.8343        89\n",
      "   label_gameplay     0.8765    0.9675    0.9198       154\n",
      "     label_visual     0.8235    0.8046    0.8140        87\n",
      "      label_audio     0.9200    0.9020    0.9109        51\n",
      "  label_technical     0.8298    0.6842    0.7500        57\n",
      "      label_price     0.7805    0.6809    0.7273        47\n",
      " label_suggestion     0.0000    0.0000    0.0000        21\n",
      "\n",
      "        micro avg     0.8646    0.8394    0.8518       654\n",
      "        macro avg     0.7485    0.7257    0.7354       654\n",
      "     weighted avg     0.8373    0.8394    0.8369       654\n",
      "      samples avg     0.8457    0.8035    0.8042       654\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# best hyperparameter from 16 trials, before it stopped halfway\n",
    "# ╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
    "# │ Trial name            status         ...ccumulation_steps     num_train_epochs     learning_rate     weight_decay     warmup_ratio     iter     total time (s)     eval_loss     eval_precision     eval_recall     eval_f1 │\n",
    "# ├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
    "# │ _objective_47d46dc3   TERMINATED                       16                    5       4.95377e-05      0.000603811        0.0214077        5           441.176       0.348702           0.860371        0.854684    0.857066 │\n",
    "# ╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
    "run(\n",
    "    model_name='jinaai/jina-embeddings-v2-base-en',\n",
    "    gradient_accumulation_steps=16,\n",
    "    num_train_epochs=5,\n",
    "    learning_rate=4.9537713401096075e-05,\n",
    "    weight_decay=0.0006038110820661773,\n",
    "    warmup_ratio=0.021407687322013313\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
