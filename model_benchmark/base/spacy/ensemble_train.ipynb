{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    f1_score,\n",
    "    classification_report,\n",
    ")\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import spacy\n",
    "from spacy.tokens import DocBin\n",
    "from spacy.cli.train import train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.blank(\"pt\")\n",
    "df_train = pd.read_csv('../../../dataset/v1/train.csv')\n",
    "df_test = pd.read_csv('../../../dataset/v1/test.csv')\n",
    "\n",
    "labels = df_train.columns[3:].to_list()\n",
    "X_train = list(range(0, df_train.shape[0]))\n",
    "y_train = df_train[labels].to_numpy()\n",
    "y_test = df_test[labels].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = DocBin()\n",
    "for i in range(df_train.shape[0]):\n",
    "    doc = nlp(df_train.iat[i, 2])\n",
    "    for j, label in enumerate(df_train.columns[3:].to_list()):\n",
    "        doc.cats[label] = df_train.iat[i, 3+j]\n",
    "    db.add(doc)\n",
    "db.to_disk('./dataset/train.spacy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dummy data for dev\n",
    "db = DocBin()\n",
    "doc = nlp('I like this game, it has decent plot and good graphic. Also run on Steam Deck smoothly')\n",
    "doc.cats['label_recommended'] = 1\n",
    "doc.cats['label_story'] = 1\n",
    "doc.cats['label_gameplay'] = 0\n",
    "doc.cats['label_visual'] = 1\n",
    "doc.cats['label_audio'] = 0\n",
    "doc.cats['label_technical'] = 1\n",
    "doc.cats['label_price'] = 0\n",
    "doc.cats['label_suggestion'] = 1\n",
    "db.add(doc)\n",
    "db.to_disk('./dataset/dev.dummy.spacy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;4mℹ Saving to output directory: output\u001b[0m\n",
      "\u001b[38;5;4mℹ Using CPU\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== Initializing pipeline ===========================\u001b[0m\n",
      "\u001b[38;5;2m✔ Initialized pipeline\u001b[0m\n",
      "\u001b[1m\n",
      "============================= Training pipeline =============================\u001b[0m\n",
      "\u001b[38;5;4mℹ Pipeline: ['tok2vec', 'textcat_multilabel']\u001b[0m\n",
      "\u001b[38;5;4mℹ Initial learn rate: 0.001\u001b[0m\n",
      "E    #       LOSS TOK2VEC  LOSS TEXTC...  CATS_SCORE  CATS_MACRO_P  CATS_MACRO_R  CATS_MACRO_F  SCORE \n",
      "---  ------  ------------  -------------  ----------  ------------  ------------  ------------  ------\n",
      "  0       0          0.02           0.35        0.00         25.00         25.00         25.00    0.25\n",
      "  0     200          1.13          52.73        0.00         12.50         12.50         12.50    0.12\n",
      "  0     400          1.17          48.14        0.00          0.00          0.00          0.00    0.00\n",
      "  0     600          1.52          42.50        0.00         12.50         12.50         12.50    0.12\n",
      "  0     800          1.07          40.86        0.00         12.50         12.50         12.50    0.12\n",
      "  1    1000          0.90          37.12        0.00         25.00         25.00         25.00    0.25\n",
      "  1    1200          1.43          34.79        0.00         37.50         37.50         37.50    0.38\n",
      "  1    1400          1.05          34.44        0.00         25.00         25.00         25.00    0.25\n",
      "  2    1600          1.52          31.38        0.00         25.00         25.00         25.00    0.25\n",
      "  2    1800          1.62          27.32        0.00         37.50         37.50         37.50    0.38\n",
      "  2    2000          1.60          26.44        0.00         25.00         25.00         25.00    0.25\n",
      "  2    2200          1.62          26.69        0.00         25.00         25.00         25.00    0.25\n",
      "  3    2400          1.56          25.63        0.00         25.00         25.00         25.00    0.25\n",
      "  3    2600          1.63          20.58        0.00         25.00         25.00         25.00    0.25\n",
      "  3    2800          1.97          21.47        0.00         25.00         25.00         25.00    0.25\n",
      "  4    3000          1.65          18.00        0.00         37.50         37.50         37.50    0.38\n",
      "\u001b[38;5;2m✔ Saved pipeline to output directory\u001b[0m\n",
      "output/model-last\n"
     ]
    }
   ],
   "source": [
    "# ignore score since we use dummy data for dev\n",
    "train('./config.cfg', output_path='./output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tok2vec', 'textcat_multilabel']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp = spacy.load('./output/model-last')\n",
    "nlp.pipe_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label_recommended': 0.19961223006248474,\n",
       " 'label_story': 0.008869870565831661,\n",
       " 'label_gameplay': 0.4891369044780731,\n",
       " 'label_visual': 0.02876739390194416,\n",
       " 'label_audio': 0.0017880821833387017,\n",
       " 'label_technical': 0.033372193574905396,\n",
       " 'label_price': 0.215810626745224,\n",
       " 'label_suggestion': 0.06886571645736694}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp('I like this game so much').cats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 1., ..., 1., 0., 0.],\n",
       "       [1., 1., 1., ..., 0., 0., 0.],\n",
       "       [1., 1., 1., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 1., ..., 1., 0., 0.],\n",
       "       [0., 0., 1., ..., 1., 0., 0.],\n",
       "       [1., 1., 1., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = np.zeros(shape=y_test.shape)\n",
    "for i, doc in enumerate(nlp.pipe(df_test['cleaned_review'].to_list())):\n",
    "    y_pred[i, :] = list(doc.cats.values())\n",
    "mask_pos = y_pred > 0.5\n",
    "y_pred[mask_pos] = 1.0\n",
    "y_pred[~mask_pos] = 0.0\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall accuracy: 0.195\n",
      "Accuracy label_recommended: 0.805\n",
      "Accuracy label_story: 0.79\n",
      "Accuracy label_gameplay: 0.82\n",
      "Accuracy label_visual: 0.735\n",
      "Accuracy label_audio: 0.89\n",
      "Accuracy label_technical: 0.76\n",
      "Accuracy label_price: 0.765\n",
      "Accuracy label_suggestion: 0.89\n",
      "F1 macro: 0.6299451658099359\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "label_recommended     0.8303    0.9257    0.8754       148\n",
      "      label_story     0.7527    0.7865    0.7692        89\n",
      "   label_gameplay     0.8278    0.9675    0.8922       154\n",
      "     label_visual     0.6441    0.8736    0.7415        87\n",
      "      label_audio     0.7101    0.9608    0.8167        51\n",
      "  label_technical     0.5692    0.6491    0.6066        57\n",
      "      label_price     0.5000    0.2553    0.3380        47\n",
      " label_suggestion     0.0000    0.0000    0.0000        21\n",
      "\n",
      "        micro avg     0.7413    0.8104    0.7743       654\n",
      "        macro avg     0.6043    0.6773    0.6299       654\n",
      "     weighted avg     0.7118    0.8104    0.7524       654\n",
      "      samples avg     0.7281    0.7809    0.7335       654\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def evaluate(y_test, y_pred, labels):\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f'Overall accuracy: {accuracy}')\n",
    "    for idx, label in enumerate(labels):\n",
    "        label_accuracy = accuracy_score(y_test[:, idx], y_pred[:, idx])\n",
    "        print(f'Accuracy {label}: {label_accuracy}')\n",
    "\n",
    "    f1 = f1_score(y_test, y_pred, average='macro')\n",
    "    print(f'F1 macro: {f1}')\n",
    "    print(\n",
    "        classification_report(y_test, y_pred, target_names=labels, digits=4, zero_division=0)\n",
    "    )\n",
    "\n",
    "evaluate(y_test, y_pred, labels)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
